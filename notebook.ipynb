{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "S-JOBgLOApRX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "hpGQM3uhmTiG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRuWyN4mbnqw",
        "outputId": "220e7ad7-7036-4d27-a083-5c9b645796db"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "g-71YTlPAyeS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da26eeb7-f9c6-4201-ab1a-d1fcf9e721c7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "data_dir = '/content/drive/MyDrive/Dataset'  # change if needed\n",
        "batch_size = 32\n",
        "num_epochs = 50\n",
        "img_size = 224"
      ],
      "metadata": {
        "id": "XHHmN9c6AygU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data transforms\n",
        "transform = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "id": "WIX6XYTIAyiX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasets and loaders\n",
        "dataset = datasets.ImageFolder(data_dir, transform=transform['train'])\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "val_dataset.dataset.transform = transform['val']\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "q0Wp3oMsAypc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26dfe9c6-1605-4600-bbf9-ddba22b16264"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrained ResNet-50\n",
        "model = models.resnet50(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, len(dataset.classes))  # Output layer for your classes\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "-D_5HZ0iA7ky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0251cd5-7a52-47c1-85e8-0bca7197c079"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 190MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "1mMue9OhA7m1"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    epoch_loss = running_loss / train_size\n",
        "    epoch_acc = running_corrects.double() / train_size\n",
        "    print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_corrects = 0\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_corrects += torch.sum(preds == labels.data)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_acc = val_corrects.double() / val_size\n",
        "    print(f\"Val Accuracy: {val_acc:.4f}\")"
      ],
      "metadata": {
        "id": "ggi4crQZA7ov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a9f5329-48ec-44ea-8564-7d29a979b234"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/50\n",
            "Train Loss: 2.2638 Acc: 0.4031\n",
            "Val Accuracy: 0.6284\n",
            "\n",
            "Epoch 2/50\n",
            "Train Loss: 0.7466 Acc: 0.8330\n",
            "Val Accuracy: 0.7257\n",
            "\n",
            "Epoch 3/50\n",
            "Train Loss: 0.2071 Acc: 0.9727\n",
            "Val Accuracy: 0.8093\n",
            "\n",
            "Epoch 4/50\n",
            "Train Loss: 0.0697 Acc: 0.9932\n",
            "Val Accuracy: 0.8307\n",
            "\n",
            "Epoch 5/50\n",
            "Train Loss: 0.0310 Acc: 0.9981\n",
            "Val Accuracy: 0.8171\n",
            "\n",
            "Epoch 6/50\n",
            "Train Loss: 0.0208 Acc: 0.9995\n",
            "Val Accuracy: 0.8249\n",
            "\n",
            "Epoch 7/50\n",
            "Train Loss: 0.0334 Acc: 0.9951\n",
            "Val Accuracy: 0.7568\n",
            "\n",
            "Epoch 8/50\n",
            "Train Loss: 0.0562 Acc: 0.9903\n",
            "Val Accuracy: 0.7957\n",
            "\n",
            "Epoch 9/50\n",
            "Train Loss: 0.0357 Acc: 0.9946\n",
            "Val Accuracy: 0.7607\n",
            "\n",
            "Epoch 10/50\n",
            "Train Loss: 0.0493 Acc: 0.9888\n",
            "Val Accuracy: 0.7607\n",
            "\n",
            "Epoch 11/50\n",
            "Train Loss: 0.0672 Acc: 0.9864\n",
            "Val Accuracy: 0.7860\n",
            "\n",
            "Epoch 12/50\n",
            "Train Loss: 0.0516 Acc: 0.9869\n",
            "Val Accuracy: 0.7724\n",
            "\n",
            "Epoch 13/50\n",
            "Train Loss: 0.0641 Acc: 0.9839\n",
            "Val Accuracy: 0.7821\n",
            "\n",
            "Epoch 14/50\n",
            "Train Loss: 0.1217 Acc: 0.9669\n",
            "Val Accuracy: 0.7802\n",
            "\n",
            "Epoch 15/50\n",
            "Train Loss: 0.0431 Acc: 0.9893\n",
            "Val Accuracy: 0.8093\n",
            "\n",
            "Epoch 16/50\n",
            "Train Loss: 0.0295 Acc: 0.9927\n",
            "Val Accuracy: 0.8035\n",
            "\n",
            "Epoch 17/50\n",
            "Train Loss: 0.0608 Acc: 0.9854\n",
            "Val Accuracy: 0.8054\n",
            "\n",
            "Epoch 18/50\n",
            "Train Loss: 0.0139 Acc: 0.9985\n",
            "Val Accuracy: 0.8230\n",
            "\n",
            "Epoch 19/50\n",
            "Train Loss: 0.0070 Acc: 0.9990\n",
            "Val Accuracy: 0.8307\n",
            "\n",
            "Epoch 20/50\n",
            "Train Loss: 0.0219 Acc: 0.9956\n",
            "Val Accuracy: 0.7938\n",
            "\n",
            "Epoch 21/50\n",
            "Train Loss: 0.0107 Acc: 0.9990\n",
            "Val Accuracy: 0.8171\n",
            "\n",
            "Epoch 22/50\n",
            "Train Loss: 0.0241 Acc: 0.9961\n",
            "Val Accuracy: 0.8035\n",
            "\n",
            "Epoch 23/50\n",
            "Train Loss: 0.0391 Acc: 0.9893\n",
            "Val Accuracy: 0.8054\n",
            "\n",
            "Epoch 24/50\n",
            "Train Loss: 0.0578 Acc: 0.9854\n",
            "Val Accuracy: 0.7743\n",
            "\n",
            "Epoch 25/50\n",
            "Train Loss: 0.0226 Acc: 0.9956\n",
            "Val Accuracy: 0.8016\n",
            "\n",
            "Epoch 26/50\n",
            "Train Loss: 0.0099 Acc: 0.9981\n",
            "Val Accuracy: 0.8288\n",
            "\n",
            "Epoch 27/50\n",
            "Train Loss: 0.0053 Acc: 0.9990\n",
            "Val Accuracy: 0.8268\n",
            "\n",
            "Epoch 28/50\n",
            "Train Loss: 0.0047 Acc: 0.9990\n",
            "Val Accuracy: 0.8191\n",
            "\n",
            "Epoch 29/50\n",
            "Train Loss: 0.0076 Acc: 0.9985\n",
            "Val Accuracy: 0.8288\n",
            "\n",
            "Epoch 30/50\n",
            "Train Loss: 0.0078 Acc: 0.9995\n",
            "Val Accuracy: 0.8366\n",
            "\n",
            "Epoch 31/50\n",
            "Train Loss: 0.0033 Acc: 1.0000\n",
            "Val Accuracy: 0.8502\n",
            "\n",
            "Epoch 32/50\n",
            "Train Loss: 0.0062 Acc: 0.9990\n",
            "Val Accuracy: 0.8210\n",
            "\n",
            "Epoch 33/50\n",
            "Train Loss: 0.0149 Acc: 0.9966\n",
            "Val Accuracy: 0.8132\n",
            "\n",
            "Epoch 34/50\n",
            "Train Loss: 0.0549 Acc: 0.9864\n",
            "Val Accuracy: 0.7607\n",
            "\n",
            "Epoch 35/50\n",
            "Train Loss: 0.0547 Acc: 0.9873\n",
            "Val Accuracy: 0.7626\n",
            "\n",
            "Epoch 36/50\n",
            "Train Loss: 0.0270 Acc: 0.9937\n",
            "Val Accuracy: 0.7782\n",
            "\n",
            "Epoch 37/50\n",
            "Train Loss: 0.0343 Acc: 0.9893\n",
            "Val Accuracy: 0.7802\n",
            "\n",
            "Epoch 38/50\n",
            "Train Loss: 0.0274 Acc: 0.9937\n",
            "Val Accuracy: 0.7802\n",
            "\n",
            "Epoch 39/50\n",
            "Train Loss: 0.0391 Acc: 0.9912\n",
            "Val Accuracy: 0.7879\n",
            "\n",
            "Epoch 40/50\n",
            "Train Loss: 0.0361 Acc: 0.9898\n",
            "Val Accuracy: 0.7763\n",
            "\n",
            "Epoch 41/50\n",
            "Train Loss: 0.0274 Acc: 0.9937\n",
            "Val Accuracy: 0.8054\n",
            "\n",
            "Epoch 42/50\n",
            "Train Loss: 0.0244 Acc: 0.9961\n",
            "Val Accuracy: 0.8366\n",
            "\n",
            "Epoch 43/50\n",
            "Train Loss: 0.0169 Acc: 0.9961\n",
            "Val Accuracy: 0.7957\n",
            "\n",
            "Epoch 44/50\n",
            "Train Loss: 0.0363 Acc: 0.9937\n",
            "Val Accuracy: 0.7840\n",
            "\n",
            "Epoch 45/50\n",
            "Train Loss: 0.0592 Acc: 0.9864\n",
            "Val Accuracy: 0.7879\n",
            "\n",
            "Epoch 46/50\n",
            "Train Loss: 0.0401 Acc: 0.9912\n",
            "Val Accuracy: 0.8191\n",
            "\n",
            "Epoch 47/50\n",
            "Train Loss: 0.0130 Acc: 0.9966\n",
            "Val Accuracy: 0.8210\n",
            "\n",
            "Epoch 48/50\n",
            "Train Loss: 0.0492 Acc: 0.9903\n",
            "Val Accuracy: 0.8093\n",
            "\n",
            "Epoch 49/50\n",
            "Train Loss: 0.0452 Acc: 0.9893\n",
            "Val Accuracy: 0.7977\n",
            "\n",
            "Epoch 50/50\n",
            "Train Loss: 0.0728 Acc: 0.9830\n",
            "Val Accuracy: 0.8210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=dataset.classes))"
      ],
      "metadata": {
        "id": "bV-9SCcJA7qe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f0691d7-b06a-4612-f760-3b3d69cc1e77"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "      Akshay Kumar       0.77      0.91      0.83        11\n",
            "Alexandra Daddario       0.68      1.00      0.81        17\n",
            "        Alia Bhatt       0.80      0.44      0.57        18\n",
            "  Amitabh Bachchan       1.00      0.93      0.97        15\n",
            "      Andy Samberg       0.57      0.94      0.71        18\n",
            "    Anushka Sharma       0.76      0.87      0.81        15\n",
            "     Billie Eilish       0.86      1.00      0.93        19\n",
            "         Brad Pitt       0.87      0.81      0.84        16\n",
            "    Camila Cabello       0.88      0.91      0.89        23\n",
            "   Charlize Theron       0.54      0.64      0.58        11\n",
            "       Claire Holt       0.83      0.59      0.69        17\n",
            "      Courtney Cox       0.91      0.77      0.83        13\n",
            "    Dwayne Johnson       1.00      0.89      0.94         9\n",
            "   Elizabeth Olsen       0.89      0.67      0.76        12\n",
            "   Ellen Degeneres       0.95      0.95      0.95        19\n",
            "      Henry Cavill       0.79      0.92      0.85        24\n",
            "    Hrithik Roshan       0.86      0.71      0.77        17\n",
            "      Hugh Jackman       0.95      0.78      0.86        23\n",
            "      Jessica Alba       0.79      0.75      0.77        20\n",
            "           Kashyap       0.29      0.67      0.40         3\n",
            "       Lisa Kudrow       0.79      1.00      0.88        15\n",
            "     Margot Robbie       0.62      0.73      0.67        11\n",
            "            Marmik       0.50      0.25      0.33         4\n",
            "   Natalie Portman       0.87      0.87      0.87        30\n",
            "   Priyanka Chopra       0.88      0.68      0.77        22\n",
            "  Robert Downey Jr       0.92      0.79      0.85        29\n",
            "     Roger Federer       0.85      0.94      0.89        18\n",
            "        Tom Cruise       1.00      0.73      0.85        15\n",
            " Vijay Deverakonda       0.82      0.95      0.88        19\n",
            "       Virat Kohli       1.00      0.73      0.84        11\n",
            "         Zac Efron       1.00      0.90      0.95        20\n",
            "\n",
            "          accuracy                           0.82       514\n",
            "         macro avg       0.81      0.80      0.79       514\n",
            "      weighted avg       0.84      0.82      0.82       514\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "save_path = '/content/drive/MyDrive/resnet50_finetuned_2.pth'\n",
        "torch.save(model.state_dict(), save_path)"
      ],
      "metadata": {
        "id": "NWYw-EGWA7sk"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}